title,article
预训练模型的训练任务在 MLM 之外还有哪些有效方式？,"MLM和NSP分别对应的是Token级别和句子级别两个粒度的任务，可以替代NSP的任务还真不少，粘一些任务介绍放到这里（懒得翻译了），有兴趣的可以参看这篇On Losses for Modern Language Models：

Token级别的任务：

1. Term Frequency prediction (TF): Regression predicting a token’s frequency in the rest of the document. The frequency is re-scaled between 0 and 10 per document.

2. Term Frequency-Inverse Document Frequency prediction (TF-IDF): Regression predicting a token’s tf-idf that has been re-scaled between 0 and 10 per document.

3. Sentence Boundary Objective (SBO): Predict the masked token given the embeddings of the adjacent tokens.

4. Trigram-Shuffling (TGS): 6-way classification predicting the original order of shuffled tri-grams.

5. Token Corruption Prediction (TCP): Binary classification of whether a token has been corrupted (inserted, replaced, permuted) or not.

6. Capitalization Prediction (Cap.): Binary, whether a token is capitalized or not.

7. Token Length Prediction (TLP): Regression to predict the length of the WordPiece token.

句子级别的任务：

8. Next Sentence Prediction (NSP): Binary, whether the second sentence follows the first or comes from a separate document.

9. Adjacent Sentence Prediction (ASP): 3-way classification whether the second sentence proceeds the first, precedes the first, or they come from separate documents.

10. Sentence Ordering (SO): Binary, predicting if the two sentences are in or out of order.

11. Sentence Distance Prediction (SDP): 3-way classification of whether the second sentence proceeds, the two sentences are noncontiguous from the same document, or come from separate documents.

12. Sentence Corruption Prediction (SCP): Binary classification of whether a tokens in a sentence have been corrupted (inserted, replaced, permuted) or not.

13. Quick Thoughts variant (QT): Split each batch into two, where the second half contains the subsequent sentences of the first half (e.g. with batch size 32, sentence 17 follows sentence 1, sentence 18 follows sentence 2,...). We use an energy-based model to predict the correct continuation for each sentence in the first half where the energy between two sentences is defined by the negative cosine similarity of their [CLS] embeddings. We use one model to encode both halves concurrently. See Figure 1.

14. FastSent variant (FS): Split each batch into two, where the second half contains the subsequent sentences of the first half (same as QT above). The loss is defined as cross-entropy between 1.0 and the cosine similarity of a sentence [CLS] embedding and the other sentence token embeddings ([CLS] embedding from the first half with token embeddings from the second half and [CLS] embeddings from second half with token embeddigns from the first half). We use one model to encode both halves concurrently.

p.s. 关于问题描述中NSP作用不大的说法，以往一般认为因为任务形式太简单会使模型关注一些浅显的lexical特征，但是其实也有文章实验表明在特定场景（例如小规模预训练模型）下，BERT style（MLM+NSP）的预训练结果会强于RoBERTa style（仅MLM）：

所以这仍然是一个有待讨论的观点。"
如何通俗易懂地解释卷积？,"对卷积的困惑

卷积这个概念，很早以前就学过，但是一直没有搞懂。教科书上通常会给出定义，给出很多性质，也会用实例和图形进行解释，但究竟为什么要这么设计，这么计算，背后的意义是什么，往往语焉不详。作为一个学物理出身的人，一个公式倘若倘若给不出结合实际的直观的通俗的解释（也就是背后的“物理”意义），就觉得少了点什么，觉得不是真的懂了。

教科书上一般定义函数 ​的卷积 ​如下：

连续形式：​

​​离散形式：​

​并且也解释了，先对g函数进行翻转，相当于在数轴上把g函数从右边褶到左边去，也就是卷积的“卷”的由来。

然后再把g函数平移到n，在这个位置对两个函数的对应点相乘，然后相加，这个过程是卷积的“积”的过程。

这个只是从计算的方式上对公式进行了解释，从数学上讲无可挑剔，但进一步追问，为什么要先翻转再平移，这么设计有何用意？还是有点费解。

在知乎，已经很多的热心网友对卷积举了很多形象的例子进行了解释，如卷地毯、丢骰子、打耳光、存钱等等。读完觉得非常生动有趣，但过细想想，还是感觉有些地方还是没解释清楚，甚至可能还有瑕疵，或者还可以改进（这些后面我会做一些分析）。

带着问题想了两个晚上，终于觉得有些问题想通了，所以就写出来跟网友分享，共同学习提高。不对的地方欢迎评论拍砖。。。

明确一下，这篇文章主要想解释两个问题：

1. 卷积这个名词是怎么解释？“卷”是什么意思？“积”又是什么意思？

2. 卷积背后的意义是什么，该如何解释？

考虑的应用场景

为了更好地理解这些问题，我们先给出两个典型的应用场景：

1. 信号分析

一个输入信号f(t)，经过一个线性系统（其特征可以用单位冲击响应函数g(t)描述）以后，输出信号应该是什么？实际上通过卷积运算就可以得到输出信号。

2. 图像处理

输入一幅图像f(x,y)，经过特定设计的卷积核g(x,y)进行卷积处理以后，输出图像将会得到模糊，边缘强化等各种效果。

对卷积的理解

对卷积这个名词的理解：所谓两个函数的卷积，本质上就是先将一个函数翻转，然后进行滑动叠加。

在连续情况下，叠加指的是对两个函数的乘积求积分，在离散情况下就是加权求和，为简单起见就统一称为叠加。

整体看来是这么个过程：

翻转——>滑动——>叠加——>滑动——>叠加——>滑动——>叠加.....

多次滑动得到的一系列叠加值，构成了卷积函数。

卷积的“卷”，指的的函数的翻转，从 g(t) 变成 g(-t) 的这个过程；同时，“卷”还有滑动的意味在里面（吸取了网友李文清的建议）。如果把卷积翻译为“褶积”，那么这个“褶”字就只有翻转的含义了。

卷积的“积”，指的是积分/加权求和。

有些文章只强调滑动叠加求和，而没有说函数的翻转，我觉得是不全面的；有的文章对“卷”的理解其实是“积”，我觉得是张冠李戴。

对卷积的意义的理解：

1. 从“积”的过程可以看到，我们得到的叠加值，是个全局的概念。以信号分析为例，卷积的结果是不仅跟当前时刻输入信号的响应值有关，也跟过去所有时刻输入信号的响应都有关系，考虑了对过去的所有输入的效果的累积。在图像处理的中，卷积处理的结果，其实就是把每个像素周边的，甚至是整个图像的像素都考虑进来，对当前像素进行某种加权处理。所以说，“积”是全局概念，或者说是一种“混合”，把两个函数在时间或者空间上进行混合。

2. 那为什么要进行“卷”？直接相乘不好吗？我的理解，进行“卷”（翻转）的目的其实是施加一种约束，它指定了在“积”的时候以什么为参照。在信号分析的场景，它指定了在哪个特定时间点的前后进行“积”，在空间分析的场景，它指定了在哪个位置的周边进行累积处理。

举例说明

下面举几个例子说明为什么要翻转，以及叠加求和的意义。

例1：信号分析

如下图所示，输入信号是 f(t) ，是随时间变化的。系统响应函数是 g(t) ，图中的响应函数是随时间指数下降的，它的物理意义是说：如果在 t=0 的时刻有一个输入，那么随着时间的流逝，这个输入将不断衰减。换言之，到了 t=T时刻，原来在 t=0 时刻的输入f(0)的值将衰减为f(0)g(T)。

​

​​考虑到信号是连续输入的，也就是说，每个时刻都有新的信号进来，所以，最终输出的是所有之前输入信号的累积效果。如下图所示，在T=10时刻，输出结果跟图中带标记的区域整体有关。其中，f(10)因为是刚输入的，所以其输出结果应该是f(10)g(0)，而时刻t=9的输入f(9)，只经过了1个时间单位的衰减，所以产生的输出应该是 f(9)g(1)，如此类推，即图中虚线所描述的关系。这些对应点相乘然后累加，就是T=10时刻的输出信号值，这个结果也是f和g两个函数在T=10时刻的卷积值。

​

​​显然，上面的对应关系看上去比较难看，是拧着的，所以，我们把g函数对折一下，变成了g(-t)，这样就好看一些了。看到了吗？这就是为什么卷积要“卷”，要翻转的原因，这是从它的物理意义中给出的。

​

​​上图虽然没有拧着，已经顺过来了，但看上去还有点错位，所以再进一步平移T个单位，就是下图。它就是本文开始给出的卷积定义的一种图形的表述：

​

​​所以，在以上计算T时刻的卷积时，要维持的约束就是： t+ (T-t) = T 。这种约束的意义，大家可以自己体会。

例2：丢骰子

在本问题 如何通俗易懂地解释卷积？中排名第一的 马同学在中举了一个很好的例子（下面的一些图摘自马同学的文章，在此表示感谢），用丢骰子说明了卷积的应用。

要解决的问题是：有两枚骰子，把它们都抛出去，两枚骰子点数加起来为4的概率是多少?

​

​​分析一下，两枚骰子点数加起来为4的情况有三种情况：1+3=4， 2+2=4, 3+1=4

因此，两枚骰子点数加起来为4的概率为：

​​写成卷积的方式就是：​

​​在这里我想进一步用上面的翻转滑动叠加的逻辑进行解释。

首先，因为两个骰子的点数和是4，为了满足这个约束条件，我们还是把函数 g 翻转一下，然后阴影区域上下对应的数相乘，然后累加，相当于求自变量为4的卷积值，如下图所示：

​

​​进一步，如此翻转以后，可以方便地进行推广去求两个骰子点数和为 n 时的概率，为f 和 g的卷积 f*g(n)，如下图所示：​

​​由上图可以看到，函数 g 的滑动，带来的是点数和的增大。这个例子中对f和g的约束条件就是点数和，它也是卷积函数的自变量。有兴趣还可以算算，如果骰子的每个点数出现的概率是均等的，那么两个骰子的点数和n=7的时候，概率最大。

例3：图像处理

还是引用知乎问题 如何通俗易懂地解释卷积？中 马同学的例子。图像可以表示为矩阵形式（下图摘自马同学的文章）：

​

对图像的处理函数（如平滑，或者边缘提取），也可以用一个g矩阵来表示，如：

注意，我们在处理平面空间的问题，已经是二维函数了，相当于：

那么函数f和g的在（u，v）处的卷积 该如何计算呢？

按卷积的定义，二维离散形式的卷积公式应该是：

从卷积定义来看，应该是在x和y两个方向去累加（对应上面离散公式中的i和j两个下标），而且是无界的，从负无穷到正无穷。可是，真实世界都是有界的。例如，上面列举的图像处理函数g实际上是个3x3的矩阵，意味着，在除了原点附近以外，其它所有点的取值都为0。考虑到这个因素，上面的公式其实退化了，它只把坐标（u,v）附近的点选择出来做计算了。所以，真正的计算如下所示：

​

​​首先我们在原始图像矩阵中取出（u,v）处的矩阵：

然后将图像处理矩阵翻转（这个翻转有点意思，可以有几种不同的理解，其效果是等效的：（1）先沿x轴翻转，再沿y轴翻转；（2）先沿x轴翻转，再沿y轴翻转；），如下：

原始矩阵：

翻转后的矩阵：

（1）先沿x轴翻转，再沿y轴翻转

（2）先沿y轴翻转，再沿x轴翻转

计算卷积时，就可以用 和 的内积：

请注意，以上公式有一个特点，做乘法的两个对应变量a,b的下标之和都是（u,v），其目的是对这种加权求和进行一种约束。这也是为什么要将矩阵g进行翻转的原因。以上矩阵下标之所以那么写，并且进行了翻转，是为了让大家更清楚地看到跟卷积的关系。这样做的好处是便于推广，也便于理解其物理意义。实际在计算的时候，都是用翻转以后的矩阵，直接求矩阵内积就可以了。

以上计算的是（u,v）处的卷积，延x轴或者y轴滑动，就可以求出图像中各个位置的卷积，其输出结果是处理以后的图像（即经过平滑、边缘提取等各种处理的图像）。

再深入思考一下，在算图像卷积的时候，我们是直接在原始图像矩阵中取了（u,v）处的矩阵，为什么要取这个位置的矩阵，本质上其实是为了满足以上的约束。因为我们要算（u，v）处的卷积，而g矩阵是3x3的矩阵，要满足下标跟这个3x3矩阵的和是（u,v），只能是取原始图像中以（u，v）为中心的这个3x3矩阵，即图中的阴影区域的矩阵。

推而广之，如果如果g矩阵不是3x3，而是7x7，那我们就要在原始图像中取以（u，v）为中心的7x7矩阵进行计算。由此可见，这种卷积就是把原始图像中的相邻像素都考虑进来，进行混合。相邻的区域范围取决于g矩阵的维度，维度越大，涉及的周边像素越多。而矩阵的设计，则决定了这种混合输出的图像跟原始图像比，究竟是模糊了，还是更锐利了。

比如说，如下图像处理矩阵将使得图像变得更为平滑，显得更模糊，因为它联合周边像素进行了平均处理：

而如下图像处理矩阵将使得像素值变化明显的地方更为明显，强化边缘，而变化平缓的地方没有影响，达到提取边缘的目的：

对一些解释的不同意见

上面一些对卷积的形象解释，如知乎问题卷积为什么叫「卷」积？中 荆哲 ，以及问题 如何通俗易懂地解释卷积？中 马同学 等人提出的如下比喻：





​​其实图中“卷”的方向，是沿该方向进行积分求和的方向，并无翻转之意。因此，这种解释，并没有完整描述卷积的含义，对“卷”的理解值得商榷。

一些参考资料

《数字信号处理（第二版）》程乾生，北京大学出版社

《信号与系统引论》 郑君里，应启珩，杨为理，高等教育出版社"
如何理解 Graph Convolutional Network（GCN）？,"偏个题，我不说怎么理解了，说说具体怎么用。

gnn的整体应用通常分为三种，即预测节点属性，预测边的属性，预测整个图的属性。以MPNN为例（https://arxiv.org/pdf/1704.01212.pdf）。现在比较常用的模型基本都分为以下2-3个步骤：信息流入（message function）->节点更新（update function）->整图读取（readout function，也叫graph pooling）。如果是节点或边的预测只需要前两个步骤，如果是计算整个图的表示向量则需要最后一步。

message function是把每个节点邻居节点的信息整合起来。比如gcn用的是convolution，即每个节点所有邻居节点过一层mlp再加起来。

update function是把message整合的信息和这个节点之前的信息作一个叠加，常用的方法有mlp，gru等等。

这里的message和update要重复计算很多次，这样能获取更深层邻居节点的信息，例如计算1次则是某个节点所有1阶邻居节点的信息，计算2次则能获取到2阶邻居节点的信息，依次类推。

readout function是经过重复很多次message和update计算后的最后一步，即获取整个图的信息。简单的方法有直接sum；稍微复杂点的就是把之前每一次迭代过程中都sum得到一个向量，再过一层mlp，也有用attention的；更复杂的有diffpool等。

具体的图数据构建方法推荐先用networkx把具体任务的输入数据转换成一个图数据，再用dgl-pytorch进行具体的模型构建。"
你有哪些deep learning（rnn、cnn）调参的经验？,"总结一下在旷视实习两年来的炼丹经验，我主要做了一些 RL，图像质量，图像分类，GAN 相关的任务

『可复现性和一致性』

有的同学在打比赛的时候，从头到尾只维护若干份代码，每次载入前一次的训练参数，改一下代码再炼，俗称老丹。这样会有几个问题：某次引入一个 bug，过了很久才发现，然后不知道影响范围；得到一个好模型，但是不知道它是怎么来的；忘了自己的 baseline，不知道改动是正面还是负面。

要尽可能确保每一个模型有可复现性，实践上建议代码不应该在训练后再改动，训练新的模型时，把旧的代码复制一遍。得到的实验结果要开个文档记下来以便日后总结，避免遗忘。我经常通过阅读自己和别人的记录来得到灵感。

实验一致性上也要多做努力，理想状态是有合理的基准来测模型的性能，同一个代码不应该由于超参的微小改动而有显著结果差异。出现这种情况可能是数据太少或基准设置不当。

『资源利用』

对于新入行的同学，不要试图在玩具级别的数据集或任务上做靠谱的研究，比如 MNIST。

不是每一个实验都要出一个好模型，实验是为了验证结论的。如果每个实验都要 8 张卡跑两个星期，人力物力都耗不起。尽力把实验控制在单卡一天以内，理想状态是半天得一次结论。理论上来说，水多加面面多加水（加数据加计算量）的做法无限涨点。建议先设一个目标，比如说就是在一天的训练时间下做对比实验。

我的实践经验是，首先用小图小模型，比如 128 x 128 输入的 ResNet18；用 cProfile 来找性能瓶颈，比如我的某个模型，训练的时候有一大半时间耗费在等数据，数据处理中一大半时间在调用 numpy 的 round 函数，前期把精力集中在提高做实验的效率上。

『模型不 work』

先把锦上添花的东西去掉，如数据增广，玄学学习率和超参，魔幻损失函数，异形模型。如果世界上有一个非要加八个增广和 1.96e-4 学习率 42 batchsize，配上四种混合损失函数的模型，改动一点都不行，它应该存在于灵能文明。可以先造一些尽量玩具的模型，验证代码正确性。

『需要进一步改进』

先确认影响模型性能的组件。感性认识就是，数据是否需要增加或增广。模型是大了还是小了，再根据速度和精度期望开始寻找合适的模型。能用全卷积的任务，少用全连接层，参数量小。基本模型上 ResNet, Unet 结构还是主流。

当你的模型有 Batch Normalization，初始化通常不需要操心，激活函数默认 Relu 即可（某引用数万的大佬说的）。一般顺序是 Conv - BN - Relu。如果没有 BN（很多任务上，BN降低训练难度，但是可能影响最终性能 ），试着要做一些数据归一化。

虽然有至少十种激活函数，但初期用 Relu 或者和某个 paper 统一即可。优化器只推荐 Momentum 和 Adam。在这些方面做尝试意义不大，如果性能提升反倒可能说明模型不成熟。不推荐做人肉模型设计，比如把某层卷积改大一点，或者微调一下通道数。除非有特别 insight，不要自己乱设计玄学组件，以吸收别人经验为主。

超参上，learning rate 最重要，推荐了解 cosine learning rate，其次是 batchsize 和 weight decay。当你的模型还不错的时候，可以试着做数据增广和改损失函数锦上添花了。

祝读到这里的各位模型涨点！

参考文献

Bag of Tricks for Image Classification with Convolutional Neural Networks，trick 合集 1。

Must Know Tips/Tricks in Deep Neural Networks，trick 合集 2。

33条神经网络训练秘技，trick 合集 3。

26秒单GPU训练CIFAR10，工程实践。

Batch Normalization，虽然玄学，但是养活了很多炼丹师。

Searching for Activation Functions，swish 激活函数。

炼丹是玄学还是科学？我觉得炼丹是工程学。"
Pretrain Language Models,
如何培养自己深度思考的习惯？,"千万别点开！千万别点开！

因为这个回答，一旦点开，你就可能与过去的思维模式彻底告别。





就这5个习惯，我陈三十六，足足参悟了六年。

我敢说，这些习惯一旦养成，绝对会让你告别过去神经大条的思维模式，从此之后效率倍增，千万别走神，我们开始：

先点赞，快点，我瞅着你呢。

长亭外，古道边，芳草天。

怎么光收藏不点赞呢！嗨！嗨！嗨！





1、给大脑预热的习惯

不是让你拿酒精灯给大脑预热，而是让你用氧气给大脑预热。

简单的说——就是让你深呼吸。





不只是因为深呼吸可以提高神经细胞的活跃度，更因为习惯性的深呼吸，可以成为深度思考前的指示信号。





别走神，听我继续说：





你一定以为一个人每天除了睡觉的时间，大脑都保持着清醒。

但其实——大脑比你想象的要懒得多。

在一天当中，我们清醒的状态下，大脑经常在休眠。我们做出的90%以上的行为，都是“下意识行为”!





比如说，你早上起床，锁上门，下电梯，出小区，到单位…...你觉得这一系列操作下来，你思考了吗？

并没有！你只是下意识的做出习惯性的行为！你甚至会经常忘记自己有没有锁门，有没有锁车。

——我们生活中90%的场景，都是类似这种的，下意识的反应。





正是因为如此，大脑的偷懒早就已经成了习惯，所以我们很难进入真正的“深度思考”状态。





正如同运动员在进行剧烈运动之前需要热身一样，思考也需要进行热身。

就像是电脑中你需要运行一个程序之前需要下载一个驱动一样。

我们的大脑，需要一个明确的信号，来被告知它即将进入一个更加高效、更加紧张的“深度思考”的状态。





如果你还是不懂“信号”的意义，那么我们举一个生活中的例子：

你爸每次揍你的时候，都会先脱鞋，那么“脱鞋”这个动作，慢慢地就会成为他准备揍你的“信号”。



久而久之，他一脱鞋，你就直接蹿出去了。

——但其实你爸可能就是鞋里进沙子了。





一般来说，在进入烧脑的深度思考之前，我会做两次深呼吸。通过两个深呼吸的时间来调整自己的思维状态。

这样我每次都很容易开启我的“深度思考”模式了。





好，现在你随着我的节奏体会一下：

我们开始：

深呼吸





放松自己全身的肌肉





吸气，使劲吸，用鼻子，吸到不能吸为止





然后，吐气，缓慢的吐气，用嘴把所有的气吐出来。





慢一点，





我们再来一遍。





吸气，





慢慢吸，





吸满





缓缓吐气。





怎么样，是不是感觉完全不一样了

现在你的大脑已经预热了。

所以接下来的内容，才是真正的硬货，每一个点，都有可能改变你的思维状态，让你的认知直接提升一个台阶。

如果，你觉得自己不行，那就先给我点个赞，再回去好好读第一条，好好吸气。

感觉还不错的，咱们点个赞继续。





别走神哈。









2、减少低密度信息获取





你一定听说过奶头乐理论，就是用各种娱乐方式，麻醉底层人口，像安抚婴儿一般，给他们嘴里塞一个“奶头”。

虽然奶头乐战略至今不知道是真是假，但是你有没有发现，正是在这个理论被提出之后，整个社会的娱乐化加速了——明星、影视、游戏…….迅速崛起。





你一定也有这样的情况，感觉到无聊就去刷抖音，感觉迷茫就去看心灵鸡汤，感觉自卑就去打游戏……

这其实就是奶头乐的渗透，用低密度的信息让你的空虚、迷茫、自卑迅速得到满足，给你打造一个看似完美的理想生活，让你放弃自我提升。





你别动，我现在就问你一句，你有多久，没有好好读过一本书了。

我再问你一句，你有多久，没有读过一个长回答了，不用太长，就我这个回答这么长的。





woc，你仔细想想，这不恐怖么？

你竟然n久都没有深度阅读过什么东西了。

不用说思考了，你连tmd读都没读完过~~~





而且，我告诉你一个秘密——你越是想逃避的那些信息源，就越是高密度信息源

比如：干巴巴的干货回答，毫无语言张力的工具书......

只有这些东西，才能帮助你深度思考，才能提高你的认知层次和姿势水平！！

而你，自从高中毕业之后，竟然就慢慢的失去了这种能力！！





所以我劝你，当你感觉自己迷茫的时候，空闲时间很多的时候，静下心来读点书。





3、辨别信息真伪的习惯

我可以明确的说，有90%的人不具备这种能力。





在网络信息如此发达的今天，只要打开手机连接互联网，就可以接收到铺天盖地的信息。

这些信息的目的毫无疑问就是对你进行观点的输送。





今天某明星结婚了，明天又说没结婚，后天又说某明星出轨了，这些信息每天都充斥着你的眼球和神经。

观点的接收，就好比是信息代码的输入，或者说像下载软件一样，而辨别信息真伪的能力，就像是给大脑建立了一个防火墙。





这个防火墙的意义就是，让你在听到一个观点的时候首先想到的不是骂娘，而是追溯信息的真伪。

如果没有这个能力，就非常容易被别人带节奏，关键是他们的内心还非常的坚定，从来不对信息的来源进行探究和反思。





比如说，现在网上有很多，关于女权的2b言论。

“女朋友是用来讲道理的吗？”

“男生23岁前必须要有房有车有存款”

“如果节日男生没有任何表示，就说明他已经出轨了”

乍一听非常对，但其实逻辑完全错误，这种言论的提出者就是包藏祸心，想要博得关注，

而没有信息辨别能力的人，一定会疯狂的拥簇这种观点。

因为看起来，是“为了你好”，实际上是在坑害你。

但普通人根本不会想这些，高举女拳旗帜就完事儿了。





所以，当你接收到一个观点的时候，不是盲目的接受和情绪化的判断，而是进行三个反问。

1、信息的来源是否可靠？

2、这个信息传播的目的是什么？

3、他为什么会有这样的观点？

无论是什么内容，先思考这三个问题，就能帮你排除90%的假信息。









4、逻辑反推的习惯

大多数人的思维逻辑都是简单、线性、正向的，也就是“因为...所以...”的思维模式。

比如，因为你喜欢这个回答，所以你点了赞。





但因为这种正向思维很简单，也很惯性，所以很多人就会利用这种正向思维来给你设套。





比如，我们大多数人的思维惯性就是“如果一件商品的质量和口碑很好，那么它就会供不应求”。

而很多手机厂商，就会利用我们正向思维的惯性，进行“饥饿营销”。

它们就是要让你有钱还买不到手机，必须要去抢，必须要订购，必须要等一个月才能拿到手机，这就会给人一种“这款手机卖的很火爆”的错觉。

这样营销，赚的盆满钵满，这就是商家的逆向思维。









5、结构化思维的习惯

伟大的哲学家、思想家、社会活动家，沃兹基硕德曾经说过，人类的思维模式可以分为三种：

感性思维、逻辑思维、结构思维。





①感性思维，是一种点状思维，

它的特点就是用直觉、情绪对事件进行主观判断。

显然，它是三种思维中最low的一种。因为这种思维会致使一个人在未知全貌的情况下，带着情绪和偏见对一件事做出判断。

经常使用这种思维的，往往都是文化水平不高的莽汉，或者涉世不深的学生。

比如：

看到一个老人倒在地上，旁边有一个手足无措的小伙子，他们就会下意识的以为是小伙子把老人弄倒了。

不管当事人如何申辩，都要站在道德的制高点对他进行斥责。

但了解到老人其实在碰瓷的事实后，又反口斥责小伙子不该多管闲事。

你看，网络上的这种翻车的反转事件还少么？





②逻辑思维，是一种线性思维，

它指的是利用因果、逻辑关系进行正向推理。

显然，这种思维方式更加理性化，就像数学题里的证明一样，有原因才有结论。

比如:因为我这个回答很好，所以点赞数很多。





但是，线性思维的维度过于单一，经常容易忽视事物的其它方面。

比如：

我这个回答赞数多，不一定是因为我写得好，也有可能是因为我美啊。



当你看到一个女生流口水的时候，你就开始推理她肯定是饿了，但其实她也有可能是馋你的身子了。

所以，线性思维很容易导致一个人对事物的认知停留在表层，陷入盲人摸象的状态。





③结构思维，是一种面状思维，

也可以说是整体性思维，是这三种思维中最高级的思维，它把每一件事都看成一种结构。

拥有这种思维的人通常能够能高效的处理问题，也比普通人更容易进行深度思考。





结构思维通常有四个步骤：

第一、观察，

第二、判断，

第三、分析，

第四、整合





举个例子来说，

当我准备去自驾游的时候，我会先搜索设定好的目的地（观察），



然后根据评价和周边环境的图片进行决定是否去这个地方（判断），



然后设计出行路线，包养车辆，加满油，甚至设计好路上在什么地方休息，在什么地方吃饭，车上要带多少食物喝水……考虑可能发生的突发情况（分析），



最后做出一个完美的出行计划（整合），





来，下面用结构思维给我点个赞。

观察我这个回答（阅读到这儿了）

判断我这个回答（写的不错）

分析我这个回答（写了五点，都很有价值）

做出一个完美的整合（啥也不说了，点个赞）





以上。





如果你看到这里，说明你是一个能够获取高密度信息的人，为你点赞。





同时，也希望你消耗1秒钟的时间，为这个回答点个赞，让更多的人看到。"
Automatic Knowledge Graph Construction,"学习 paper： Wu X, Wu J, Fu X, et al. Automatic Knowledge Graph Construction: A Report on the 2019 ICDM/ICBK Contest[C]//2019 IEEE International Conference on Data Mining (ICDM). IEEE, 2019: 1540-1545.

摘要：自动知识图构建旨在在没有人工干预的情况下，根据特定领域或跨多个领域的非结构文本来构建知识图谱。IEEE ICDM 2019和ICBK 2019邀请了多个来自学术界和工业界的团队，参加2019知识图谱竞赛，竞赛题目是至少两个不同领域中实现自动构建知识图谱，参与者需要构建一个模型，从文本数据中提取以三元组知识，并开发一个应用程序来可视化。这篇文章是一篇比赛报道，记录了五支获奖队伍所用的构建知识图谱的模型和关键技术。

I. Introduction

A. Data Graph vs. Knowledge Graph

这里将知识图谱定义为语义图谱，包括如下三个元素：

1） Concepts . 概念可以是一个实体（例如人），属性（如年龄）或事实（如“有四扇门的红色汽车”）. 概念在图中被表示为一个节点。

. 概念可以是一个实体（例如人），属性（如年龄）或事实（如“有四扇门的红色汽车”）. 概念在图中被表示为一个节点。 2） Relations . 关系是两个节点之间的语义连接，例如“ is-a”，“ has-a”或动作（如“ becomes”）。

. 关系是两个节点之间的语义连接，例如“ is-a”，“ has-a”或动作（如“ becomes”）。 3）Background knowledge about concepts and relations. 一个概念可以具有不同的名称，例如X. Wu教授和Wu Xindong Wu博士，以及可能具有多个属性，例如身高和职业，并且一个关系可以具有不同的外观，例如“had”, “has” and“have”. The background knowledge in the form of a dictionary or an ontology can semantically link different names, attributes and appearances.

如果没有关于节点或关系的背景知识，仅有节点和连接的图，这里定义为数据图(data graph).

B. Challenges in Knowledge Graph Construction

知识图构建面临的挑战有三方面:

1) 信息丢失 information loss

2) 信息冗余 information redundancy

3) 信息重叠 information overlapping

II. THE 2019 ICDM/ICBK CONTEST

竞赛的目的是生成人在阅读一段文字时的思维模式的知识图谱，因此，比赛结果将由人类专家评判。鉴于不同的专家不可避免地会关注文本的不同部分，因此知识图谱反映人的思维模式的准确性在某种程度上是主观的。

竞赛的数据集由竞赛组织者搜集而来。 该数据集包含300篇已发布的新闻文章，这些新闻文章平均分布在四个不同的行业：汽车工程，化妆品，公共安全和餐饮服务。 每篇文章的长度在150到250个字之间，包含8-20个实体。来自上述四个行业的多位专家预先手动标记了300篇文章数据集中的120篇文章。由专家对同义的实体词进行分组和标记，并形成同义词字典，然后手动标记成对的实体词之间的语义关系。

过去在NLP论坛中曾举办过类似的竞赛，根据开放文本来构建知识图谱，但是在这些竞赛中，预先给出了实体和/或关系的预定义架构，以便随后通过信息抽取模型进行抽取。 该竞赛的新颖之处在于，没有为实体或关系预先提供任何类型的架构。

III. KEY TECHNIQUES IN CONSTRUCTING KNOWLEDGE GRAPHS

典型的知识图构建过程包括三个主要部分：信息提取 information extraction ，知识融合 knowledge fusion 和 知识处理 knowledge processing 。 该竞赛仅涉及信息提取和知识融合。

信息提取的目的是识别和分离数据源中的实体，以及这些实体的属性及其与其他实体的关系。因此，信息提取是这个过程的恰当名称，因为在这个步骤中没有直接输出实际的“知识”。信息提取涉及的两个主要技术是实体识别和关系提取。另外，在知识融合中还会涉及到co-reference resolution。

A. Entity Recognition

实体识别也被称为命名实体识别(NER)，指从数据（尤其是文本数据）中识别准确命名的实体的过程。NER技术已经从基于规则的方法过渡到统计方法：

1）基于规则的方法：在对NER的早期工作中，大多数主流NER方法背后的基本思想是手动构建一组有限的规则，然后在文本中搜索与这些规则匹配的字符串。 在后来的研究中，研究人员希望通过机器自动发现并生成规则。

2）基于机器学习的方法大致分为三个主题：模型和方法的选择，模型和方法的改进，以及特征的选择。

3）基于深度学习的方法：近年来，深度学习技术已成为机器学习以及其他许多领域一样的新研究热点，并且已成功地解决了一些NER问题。 特别是，单词向量表示为NER的典型序列化标记问题提供了强大的驱动力。 最近，'A semi-markov structured support vector machine model for high-precision named entity recognition' 提出了a neural semi-Markov structured SVM model，该模型通过在训练过程中对损失增加的推理过程中的不同类型的错误分配权重，来控制精度和召回率之间的trade-off。

关于NER任务，获奖队伍的作法：

UWA队：使用NLP工具SpaCy

Tmail队：使用Stanford OpenIE toolkit, OpenIE 5.0 , and SpaCy [13].

BUPT-IBL队：将自己的模型SC-LSTM与 Stanford CoreNLP 和 SpaCy结合。为了使用两个提取模型消除冗余实体​​，他们设计了一个字符串匹配规则。

MIDAS-IIITD队：使用NLTK 和SpaCy 进行预处理。 然后，使用NLP toolkit flair将句子拆分为成组的短语，选择其中的一些以构建输出三元组。

Lab1105队：使用了SpaCy . 此外，他们还在CoNLL 2003 NER数据集上训练了BiLSTM + CRF模型，该模型包含四种类型的实体：人员（PER），组织（ORG），位置（LOC）和其他名称（MISC）

B. Relation Extraction

与NER任务类似，早期的关系提取也多是基于规则来的。但基于规则的方法局限性很明显，为了克服这些问题，有的研究提出了监督学习的方法。监督学习的方法表现往往是好的，但需要大量的人工标注语料，有时候不可行，于是就衍生出半监督、或者无监督的方法。然而，犹豫自然语言的复杂性，这些方法都远没有达到通用的应用程度。

1）有监督的学习方法：有监督的学习方法体现了对人类注释数据进行分类的思想。 一旦经过训练，这些方法就可以通过匹配过程识别实体并提取特定的关系。 关系提取的监督学习可分为两大类：基于特征向量的方法和基于核的方法。

2）半监督方法：与上述监督方法相比，大多数半监督方法还有两个额外的步骤。 首先是预先设计一些关系类型。 第二是将适当的实体对作为种子合并到训练集中。 这些方法减轻了对大量标签的依赖。

3）通用领域的方法：放宽了对特定领域规范的需求，这意味着这些方法易于扩展，甚至可以应用于多个领域。例如TextRunner提取模型：https://github.com/Originate/text-runner

4）远监督方法：远监督方法通过将非结构化文本与知识库对齐来自动生成大量训练数据。 有的研究尝试将远程监督纳入文本处理中，以通过使语料和文本对齐来自动生成训练样本，从而提取特征训练分类器。 文献[1]提出了一个句子级模型，该模型选择有效实例并充分利用知识库中的监督信息。

5）深度学习方法：深度学习方法在NLP（自然语言处理）和图形识别方面已被证明非常强大，这激发了它们在解决关系提取问题中的应用。 常用的深度网络结构：RNNs , CNNs , combined CNNs and RNNs , and LSTMs .

C. Co-reference Resolution

当知识库中的一个实体链接到多个实体引用时，将使用共引用解析或实体解析。 例如，“President Trump”和“Donald John Trump”是同一个人，因此在将这两个实体引用连接到知识库中的一个实体之前，应将其合并。

该竞赛的五个获胜团队中有四个使用NeuralCoref [2]了。

IV. SHOWCASES

A. Awards

B. Grading Rules and Scores

将三元组从每个文本文件生成的图形与两个行业专家标记的the graph edit distance进行比较。 我们使用NetworkX[3]作为图形编辑距离的度量。 为了进行公平的比较，团队意见书中的实体词被行业专家标记的同义词词典中的词替换。

C. Showcases

需要分析的文本：“BYD debuted its E-SEED GT concept car and Song Pro SUV alongside its all-new e-series models at the Shanghai International Automobile Industry Exhibition. The company also showcased its latest Dynasty series of vehicles, which were recently unveiled at the company’s spring product launch in Beijing.”

V. CONCLUSIONS

冠军队伍UWA设计了一个流水线风格的模型：使用SpaCy提取实体，识别POS标签，并使用预定义规则对名词和动词短语进行分块。为了提取关系，他们通过提取动词、介词和后置词作为关系词来将实体映射成对。他们使用一个预先训练的基于attention的Bi-LSTM模型来补充这个过程，之后将关系划分为预定义的类型。除了基本的功能之外，这个团队还选取良好的中心节点来减少中心实体的数量。可以将多个文档同时作为输入，它们的应用程序会用同样的颜色编码实体，来表示文档中同时出现的实体。

参考"
Towards a Universal Continuous Knowledge Base,"paper link :https://arxiv.org/abs/2012.13568v1

出发点

这篇文章不是传统意义上的刷SOTA的paper，是一片真正有启发意义的paper，虽然读者可能会觉得文章中的设计并不是那种惊天地泣鬼神的效果。

说到NLP里的knowledge，大多数人应该都会想到knowledge Graph吧！没错，这是知识的一种表现形式。但知识是不是只能有这一种表现形式呢？

在这篇paper的开头就说了，知识的表现形式有两种，离散的和连续的。

离散的代表就是知识图谱，它相对来说具有一定的可解释性，但是构建这样一个知识图谱很难，是一件非常耗时和耗力的工作。而且机器挖掘算法构造出来的知识图谱深度和广度都还有待提高。

由于过去deep learning的发展，特别是随着BERT等自监督model的出现，我们都认为知识被存储在神经网络内部，那么这部分知识就是第二类，也就是连续性知识的代表。如果每种神经网络都看作是一个存储了一定量连续性知识的容器的话，那么我们可不可以这样思考：去建立一个通用的连续性知识的base，这个base可以从multiple神经网络导入知识。

所以这篇paper就提出如何去建立一个通用的存储连续性知识的base，当然这篇paper只是一次对未知领域的探索，方法并不涉及到很多高大上的东西。

方法:

作者文中提出了五个问题。

存储在神经网络中的知识到底是什么？ 怎么去设计这样一个knowledge base？ 怎么样将单个神经网络中的知识导入到base？ 怎么样将各种各样的神经网络的知识导入到base？ 怎么样从base里将知识导出到神经网络中？

作者认为储存在神经网络中的知识就是神经网络层中的参数。

那么怎么去设计这样一个knowledge base呢？作者首先认为这样一个base是一组matrix组成的，其次，采用计算机存储里面的二级结构去设计matrix的位置，我们将这组矩阵设为M。

我们将每个神经网络的导入看作是一个函数模拟的问题，为每个神经网络设计一个interface，

我们所要做的就是通过优化interface接口的参数来达到让各种各样的x通过这个interface的输出y和直接通过原网络FNN的输出尽可能接近。

对于单个神经网络的导入，也就是优化上面说的差异的loss。

对于多个神经网络的导入，可以有同步和异步，同步就是同时导入，loss为两者相加，异步导入时为了解决前导入的灾难性遗忘的问题，作者采用EWC这种weight的方式来解决。

导出其实和导入差不多，只不过去优化的是神经网络的参数，而不是interface的参数。

实验部分就略过了，没啥亮点，作者简单比较了常见网络在文本分类的两个datasets上的表现，以及通过knowledge base对连续性知识的转移的表现，将多个神经网络的知识导出后，发现性能有小幅度的提高。

思考：

这篇paper的亮点不在于实验的SOTA，而在于如何利用神经网络中的连续性知识去做task，为知识的连续性表达做出了一个整体的设计框架，当然这只是一个尝试，不过连续性知识的提出以及base的设计可以说开创了一定的先河，值得我们深思，到底神经网络中学到了什么？知识图谱有哪些局限性？知识连续性和离散性的差异？这些都是值得未来研究的方向。"
文献（论文）阅读笔记怎么写？,"建议收藏！！这三步绝对可以帮你把文献阅读速度翻几倍。想提高文献阅读效率一定要分阶段来做，不可能一开始就有很高效的阅读效率的。

我在读研期间，曾经也为提高文献阅读效率尝试了很多方法，也练就了我高效阅读文献的方法。下面详细的给大家介绍三步走的文献阅读方法，照着这个方法走，每天轻轻松松可以读几十遍文献。

步骤一初级版：打印纸质文献阅读

刚开始看文献时，强烈推荐这种方法，原因是方便做笔记、标记、总结和复习，虽说效率低了点，但对文献的理解会比较深刻。

我自己开始读文献时就是这样，把文献打印出来看，看的过程中直接标记重点，把不懂的专业词汇做注释，不懂的话直接翻译成中文来理解，还有在文献中做笔记等。这样做的好处是方便复习。

而且，看完纸质文献后你会发现，它比看电子版文献印象更加深刻，原因就是通过标记、备注和手写笔记，理解的更加深刻。

缺点：

1.这种方法的缺点是比较耗时间，开始的时候一篇文献可能要看一两天才能看完；

2.耗纸；如果导师不帮忙打印，自己打印纸质文献开支是比较大的。

建议：

1.小白在用这个阶段时只要把那些需要精读的文献打印出来，看完文献后要复习，把专业术语、词汇、句子和文献核心观点不断复习，这样后续再遇到这些专业术语时基本就能知道意思了。

2.看纸质文献要多动笔，把那些重点或者没有理解透的知识做好标记，另外把整篇文章的四个重点标记出来。

1.该文献研究了什么？

2.创新点在哪？

3.研究方法是什么？

4.得出的结论是什么？

3.所有的纸质笔记要分好类，做标签，方便后续查找。

步骤二中级版：看电子版文献，做纸质笔记

通过步骤一，你可以快速的把研究领域专业术语和研究现状了解清楚，那么接下来第二步就是要学会做文献笔记了。

纸质笔记是理解文献的非常好的方法，它更加能够锻炼你的思考和总结能力。

在看文献的时候只要做几件事，把下面几个问题总结并写在笔记本上：

1.该文献研究了什么？

2.创新点在哪？

3.研究方法是什么？

4.得出的结论是什么？

通常我们看英文文献会比较多，很多刚开始读文献的同学经常会摸不清头脑，看完没有任何收获，原因就是没有总结文献核心。

而第二步我们就要学会找出文献的重点。所以读文献时要准备一个笔记本。

首先是把文献的标题、作者、期刊、阅读日期等记在开头。

然后把上面四大问题写在笔记本上，在读文献的过程中把文献中的核心观点总结，用自己理解的话写下来，比如你看的英文文献，那就把它理解后用中文写在笔记本上。

比如：创新点有三个，总结在笔记本上时就分点罗列出来。

再比如：看文献的时候研究方法都是文字描述出来，但你在总结时最好用流程图简化，即可以加深理解，又方便查看。

缺点：

1.这一步也是比较搞时的，但是经过你第一步的练习，用这种方法看完文献要花的时间更短些，而且会更有收获。

建议：

1.要准备一个专门做文献笔记的本子；

2.精读和泛读的文献都可以做文献笔记，但是精读的文献要做好标记，方便后续复习。

3.要善于总结，看过的文献不要原话照搬到笔记本上，要转化成自己的语言。

4.一篇文献笔记尽量控制在一页纸内。

通过第二步方法练习完后，你就能知道文献研究的重点在哪里可以找；创新点在哪里看；怎么简化实验方法或流程；怎么总结结论等，反正就是看完后更加明白研究的意义。

步骤三高级版：看电子笔记，只做简单的重点总结

到了第三步，就可以做到看完文献就能知道这篇文献研究了什么问题；创新点在哪；实验方法是什么；结论是什么。

那么一篇文献需要提炼的点就更少了，只要知道它的创新点，和其他研究的区别就行。

这是最高效的一种方法，一篇文献可能不到半小时就能读研，只要通过跳读，快速获取文献的重点信息。

方法很简单，明确核心观点所在的位置，比如文献研究的问题和创新点放在引言末尾，结论部分通常在文献的总结部分等。

这时候做文献笔记就用excel表格总结关键要点就行，所有的文献可以集中在一张表上也方便复习和对比找idea。

需要模板的可以关注羊驼舍，回复［文献模板］领取

建议：

1.养成看完一遍文献后再总结的习惯，并把文献总结到Excel表格上。

2.定期做大批量文献阅读，并总结，把看过的文献总结在Excel表格上后进行对比找idea。

总结：

上面三步走的流程是蹭蹭递进的，建议开始读文献的学弟学妹最好是一步一步来。

第一步骤可以花大概两个月时间来训练，保持每周3篇文献阅读量。

第二步骤需要花费三个月左右时间来训练，保持每周3～5篇的文献阅读量。

第三步骤要花费两个月左右的时间，开始的时候可以定期的每周3～5篇文献的阅读量，后续就可以不规律的进行大批量的文献阅读，比如半个月做一次10～20篇文献的阅读，并定期总结对比找idea。

好啦，今天的分享就到这，把我读研看文献的看家本领都分享出来啦，还请大家多点赞，希望更多读研的人也能够看到这个方法。





我是暖心爱分享的羊驼学长，专注分享研究生学习干货，大家可以关注我，了解更多研究生的生活和学习经验。

我们拥有 6000 多人的研究生学习社群，如果你想加入进来，私我直接拉你进群，一起来学习吧！"
有问题，就会有答案,
"BERT 可解释性-从""头""说起","一、背景介绍

搜索场景下用户搜索的 query 和召回文章标题(title)的相关性对提升用户的搜索体验有很大帮助。query-title 分档任务要求针对 query 和 title 按文本相关性进行 5 个档位的分类(1~5 档)，各档位从需求满足及语义匹配这两方面对 query-doc 的相关度进行衡量，档位越大表示相关性越高，如 1 档表示文本和语义完全不相关，而 5 档表示文本和语义高度相关，完全符合 query 的需求。

我们尝试将 Bert 模型应用在 query-title 分档任务上，将 query 和 title 作为句对输入到 bert 中，取最后一层 cls 向量用做 5 分类(如上图)，最后得到的结果比 LSTM-Attention 交互式匹配模型要好。虽然知道了 bert能解决这个问题，我们更好奇的是""为什么""：为什么 bert 的表现能这么好？这里面有没有可解释的部分呢？

因为 Multi-head-attention 是 bert 的主要组成部分，所以我们从""头""入手，希望弄清楚各个 head 对 bert 模型有什么作用。为了研究某个 head 对模型的影响，我们需要比较有这个 head 和没有这个 head 模型的前后表现。这里定义一下 HEAD-MASK 操作，其实就是针对某个 head，直接将这个 head 的 attention 值置成 0，这样对于任何输入这个 head 都只能输出 0 向量。

通过 HEAD-MASK 操作对各个 head 进行对比实验，发现了下面几个有趣的点

attention-head 很冗余/鲁棒，去掉 20%的 head 模型不受影响

各层 transformer 之间不是串行关系，去掉一整层 attention-head 对下层影响不大

各个 head 有固定的功能

某些 head 负责分词



某些 head 提取语序关系



某些 head 负责提取 query-title 之间 term 匹配关系

下面我们开始实验正文，看看这些结论是怎么得到的

二、Bert 模型 Attention-Head 实验

attention-head 是 bert 的基本组成模块，本次实验想要研究各个 head 都对模型作出了什么贡献。通过 Mask 掉某个 head，对比模型前后表现的差异来研究这个 head 对模型有什么样的作用(对训练好的 bert 做 head-mask，不重新训练，对比测试集的表现)。

bert-base 模型共 12 层每层有 12 个 head，下面实验各个 head 提取的特征是否有明显的模式(Bert 模型为在 query-title 数据上 finetune 好的中文字模型)

2.1 Attention-Head 比较冗余

标准大小的 bert 一共有 12*12 共 144 个 head.我们尝试对训练好的 bert 模型，随机 mask 掉一定比例的 head,再在测试数据集上测试分档的准确率(五分类)。

下图的柱状图的数值表示相比于 bseline(也就是不做任何 head-mask)模型 acc 的相对提升,如+1%表示比 baseline 模型的 acc 相对提高了 1%，从下面的图可以看到，随机 mask 掉低于 20%的 head，在测试数据集上模型的 acc 不会降低，甚至当 mask 掉 10%的 head 的时候模型表现比不做 head mask 的时候还提升了 1%。当 mask 掉超过一定数量的 head 后，模型表现持续下降，mask 掉越多表现越差。

同时为了弄清楚底层和高层的 transformer 哪个对于 query-title 分类更加的重要，分别对底层(layer0 ~ layer5 )和高层(layer6~layer11)的 head 做 mask, 去掉的 head 比例控制在 0~50%(占总 head 数量)之间，50%表示去掉了底层或者是高层 100%的 head 下面的图很清晰的说明了底层和高层的 attention-head 关系，橙色部分表示只 mask 掉高层(6 - 11 层)的 head,蓝色部分表示只 mask 掉底层(0 - 5 层)的 head。

显然高层的 attention-head 非常的依赖底层的 head，底层的 attention-head 负责提取输入文本的各种特征，而高层的 attention 负责将这些特征结合起来。具体表现在当 mask 掉底层(0~5 层)的 80%的 head(图中横坐标为 40%)和 mask 掉底层的 100%的 head(图中横坐标为 50%)时，模型在测试数据集上表现下降剧烈(图中蓝色部分)，说明了去掉大部分的底层 head 后只依赖高层的 head 是不行的，高层的 head 并没有提取输入的特征。相反去掉大部分高层的 head 后模型下降的并没有那么剧烈(图中橙色部分)，说明了底层的 head 提取到了很多对于本任务有用的输入特征，这部分特征通过残差连接可以直接传导到最后一层用做分类。

这个结论后面也可以用于指导模型蒸馏，实验结果表明底层的 transformer 比高层的 transformer 更加的重要，显然我们在蒸馏模型时需要保留更多的底层的 head

那么对于模型来说是否有某些层的 head 特别能影响 query-title 分类呢？假设将 bert 中所有的 attention-head 看做一个 12*12 的方阵，下面是按行 mask 掉一整行 head 后模型在测试数据上的表现，柱状图上的数值表示相比 baseline 模型的相对提升。

可以看到 mask 掉第 5 层～第 9 层的 head 都模型都有比较大的正面提升，特别是当去掉整个第 8 层的 attention-head 的时候测试数据准确率相对提升了 2.3%，从上图可以得到两个结论：

Bert 模型非常的健壮或者是冗余度很高

Bert 模型各层之间不是串行依赖的关系，信息并不是通过一层一层 transformer 层来传递的

bert 模型非常的健壮或者是冗余度很高，直接去掉一整层的 attention-head 并不会对模型的最终表现有太大的影响。 直接去掉整层的 attention-head 模型表现并没有大幅度的下降，说明各层提取的特征信息并不是一层一层的串行传递到分类器的，而是通过残差连接直接传导到对应的层。

2.2 某些 head 负责判断词的边界(使得字模型带有分词信息)

在我们的 query-title 分档场景中，发现词粒度的 bert 和字粒度的 bert 最终的表现是差不多的，而对于 rnn 模型来说字粒度的 rnn 很难达到词粒度 rnn 的效果，我们希望研究一下为什么词粒度和字粒度的 bert 表现差不多。

使用的 bert 可视化工具bert_viz 观察各层 attention-head 的 attention 权重分布，可以发现某些 head 带有很明显的分词信息。推测这部分 attention-head 是专门用于提取分词信息的 head。当当前的字可能是词的结尾时，att 权重会偏向 sep,当这个字为词的结尾可能性越大(常见的词结尾)，sep 的权重会越高。当当前字不是词结尾时，att 会指向下一个字。这种模式非常明显，直接拿这个 attention-head 的结果用于分词准确率为 70%。

下面 gif 为我们模型中第 1 层第 3 个 head 的 attention 分布权重图，可以发现 attention 权重很明显带有词的边界信息，当当前的字是结尾时 attention 权重最大的 token 为""SEP""，若当前字不是结尾时 attention 权重最大的为下一个字。

这种用于提取分词信息的 head 有很多，且不同的 head 有不同的分词粒度，如果将多个粒度的分词综合考虑(有一个 head 分词正确就行)，则直接用 attention-head 切词的准确率在 96%，这也是为什么词粒度 bert 和字粒度 bert 表现差不多的原因。

猜测字粒度 bert 带词边界信息是通过 bert 的预训练任务 MLM 带来的，语言模型的训练使得 bert 对各个字之间的组合非常的敏感，从而能够区分词的边界信息。

2.3 某些 head 负责编码输入的顺序

我们知道 bert 的输入为 token_emb+pos_emb+seg_type_emb 这三个部分相加而成，而文本输入的顺序完全是用 pos_emb 来隐式的表达。bert 中某些 head 实际上负责提取输入中的位置信息。这种 attention-head 有明显的上下对齐的模式，如下图：

原输入: query=""京东小哥"", title=""京东小哥最近在干嘛"",bert 模型判定为 4 档

将 title 顺序打乱: query=""京东小哥"", title=""近东嘛最都在干哥小京"",bert 模型判定为2 档 将 title 顺序打乱: query=""京东小哥"", title=""近东嘛最都在干哥小京"",mask 掉 7 个怀疑用于提取语序的 head,bert 模型判定为3 档

下面的图分别对比了不做 mask，随机 mask 掉 7 个 head(重复 100 次取平均值)，mask 掉 7 个特定的 head(怀疑带有语序信息的 head) 从下面的图看到，mask 掉 7 个特定的 head 后整体分档提升为 3 档，而随机 mask 掉 7 个 head 结果仍然为 2 档，且档位概率分布和不 mask 的情况差别不大。

这个 case 说明了我们 mask 掉的 7 个特定的 head 应该是负责提取输入的顺序信息，也就是语序信息。将这部分 head mask 掉后，bert 表现比较难察觉到 title 中的乱序，从而提升了分档。

2.4 某些 head 负责 query 和 title 中相同部分的 term 匹配

query 和 title 中是否有相同的 term 是我们的分类任务中非常关键的特征，假如 query 中大部分 term 都能在 title 中找到，则 query 和 title 相关性一般比较高。如 query=""京东小哥""就能完全在 title=""京东小哥最近在干嘛""中找到，两者的文本相关性也很高。我们发现部分 attention-head 负责提取这种 term 匹配特征，这种 head 的 attention 权重分布一般如下图，可以看到上句和下句中相同 term 的权重很高(颜色越深表示权重越大)。

其中在第 2~第 4 层有 5 个 head 匹配的模式特别明显。我们发现虽然 bert 模型中 attention-head 很冗余，去掉一些 head 对模型不会有太大的影响，但是有少部分 head 对模型非常重要，下面展示这 5 个 head 对模型的影响，表格中的数值表示与 baseline 模型的 acc 相对提升值。

利用测试数据作为标准，分别测试随机 mask 掉 5 个 head 和 mask 掉 5 个指定的 head(这些 head 在 attention 可视化上都有明显的 query-title 匹配的模式)。从结果可以看到去掉这些负责 query-title 匹配的 head 后模型表现剧烈下降，只去掉这 5 个 head 就能让模型表现下降 50%。甚至 mask 掉 0~5 层其他 head，只保留这 5 个 head 时模型仍维持 baseline 模型 82%的表现，说明了 query-title 的 term 匹配在我们的任务中是非常重要的。

这也许是为什么双塔 bert 在我们的场景下表现会那么差的原因(Bert+LSTM 实验中两个模型结合最后的表现差于只使用 Bert, Bert 的输入为双塔输入)，因为 query 和 title 分别输入，使得这些 head 没有办法提取 term 的匹配特征(相当于 mask 掉了这些 head)，而这些匹配特征对于我们的分类任务是至关重要的

2.4.1 finetune 对于负责 term 匹配 attention-head 的影响

在 query-title 分档任务中 query 和 title 中是否有相同的 term 是很重要的特征，那么在 finetune 过程中负责 query-title 中相同 term 匹配的 head 是否有比较明显的增强呢？

下面以 case 为例说明： query=""我在伊朗长大"" title=""假期电影《我在伊朗长大》""

下图展示了 query-title 数据***finetune 前*****某个**负责 term 匹配的 head 的 attention 分配图

在没有 finetune 前，可以看到某些 head 也会对上下句中重复的 term 分配比较大的 attention 值，这个特质可能是来自预训练任务 NSP(上下句预测)。因为假如上句和下句有出现相同的 term，则它们是上下句的概率比较大，所以 bert 有一些 head 专门负责提取这种匹配的信息。

除了上下句相同的 term 有比较大的注意力，每个 term 对自身也有比较大的注意力权重（体现在图中对角线上的值都比较大) 为了更直观的看训练前后哪部分的 attention 值有比较大的改变，分别展示训练后 attention增强(微调前-微调后>0)和训练后 attention减弱(微调前-微调后<0)的 attention 分配图。可以观察到比较明显的几个点：

query 和 title 中 term 匹配的 attention 值变大了 从下图可以看到, query 和 title 中具有相同 term 时 attention 相比于训练前是有比较大的增强。说明在下游任务(query-title 分档)训练中增强了这个 head 的相同 term 匹配信息的抽取能力。

term 和自身的 attention 变小了 模型将重点放在找 query 和 title 中是否有相同的 term，弱化了 term 对自身的注意力权重

分隔符 sep 的 attention 值变小了。 有论文指出当某个 token 的 attention 指向 sep 时表示一种不分配的状态(即此时没有找到合适的 attention 分配方式)，在经过 finetune 后 term 指向 sep 的权重变小了，表示经过 query-title 数据训练后这个 head 的 attention 分配更加的明确了。

2.4.2 是否有某个 head 特别能影响模型

从上面的实验可以看到，bert 模型有比较多冗余的 head。去掉一部分这些 head 并不太影响模型，但是有少部分 head 特别能影响模型如上面提到的负责提取上下句中 term 匹配信息的 head，只去掉 5 个这种 head 就能让模型的表现下降 50%。那么是否有某个 head 特别能影响结果呢？

下面实验每次只 mask 掉一个 head，看模型在测试数据中表现是否上升/下降。下图中将 bert 的 144 个 head 看作 12X12 的矩阵，矩阵内每个元素表示去掉这个 head 后模型在测试数据上的表现。其中 0 表示去掉后对模型的影响不太大。元素内的值表示相对于 baseline 的表现提升，如+1%表示相比 baseline 的 acc 提高了 1%。

可以看到对于 bert 的大部分 head，单独去掉这个 head 对模型并不会造成太大的影响，而有少部分 head 确实特别能影响模型，比如负责上下句(query-title)中相同 term 匹配的 head。即使去掉一个这种 head 也会使得模型的表现下降。同时注意到高层(第 10 层)有一个 head 去掉后模型表现变化也很大，实验发现这个 head 功能是负责抽取底层 head 输出的特征，也就是 3-4 层中 head 抽取到输入的 query-title 有哪些相同 term 特征后，这部分信息会传递到第 10 层进一步进行提取，最后影响分类。

2.4.3 高层 head 是如何提取底层 head 特征-一个典型 case

上图中，在第 10 层有一个 head 去掉后特别能影响模型，观察其 attention 的分布，cls 的 attention 都集中在 query 和 title 中相同的 term 上，似乎是在对底层 term 匹配 head 抽取到的特征进一步的提取，将这种匹配特征保存到 cls 中(cls 最后一层会用于分类)。

在没有做任何 head-mask 时, 可以看到 cls 的 attention 主要分配给和 query 和 title 中的共同 term ""紫熨斗""，而 mask 掉 5 个 2~4 层的 head(具有 term 匹配功能)时, 第 10 层的 cls 注意力分配明显被改变，分散到更多的 term 中。

这个 case 展示了高层 attention-head 是如何依赖底层的 head 的特征，进一步提取底层的特征并最后作为重要特征用于 query-title 分类。

结语

本文主要探讨了在 query-title 分类场景下,bert 模型的可解释性。主要从 attention-head 角度入手，发现 attention 一方面非常的冗余，去掉一部分 head 其实不会对模型造成多大的影响。另外一方面有一些 head 却非常的能影响模型，即使去掉一个都能让模型表现变差不少。同时发现不同的 head 实际上有特定的功能，比如底层的 head 负责对输入进行特征提取，如分词、提取输入的语序关系、提取 query 和 title(也就是上下句)中相同的 term 信息等。这部分底层的 head 提取到的特征会通过残差连接送到高层的 head 中，高层 head 会对这部分特征信息进行进一步融合，最终作为分类特征输入到分类器中。

本文重点讨论了哪些 head 是对模型有正面作用，也就是去掉这些 head 后模型表现变差了。但是如果知道了哪些 head 为什么对模型有负面作用，也就是为什么去掉某些 head 模型效果会更好，实际上对于我们有更多的指导作用。这部分信息能够帮助我们在模型加速，提升模型表现上少走弯路。

参考文献

[1] Clark K, Khandelwal U, Levy O, et al. What Does BERT Look At? An Analysis of BERT's Attention[J]. arXiv preprint arXiv:1906.04341, 2019.

[2] Vig J. A multiscale visualization of attention in the transformer model[J]. arXiv preprint arXiv:1906.05714, 2019.

作者：vincehou，腾讯 TEG 应用研究员

更多干货尽在腾讯技术，官方QQ交流群已建立，交流讨论可加：957411539。"
NLP文本匹配问题的本质是不是 对于要预测的句子，遍历候选句子 从训练数据集里寻找最相似的pair？,"谢霍华德大佬的邀啊，受宠若惊。

咱先把定义弄明白吧。

文本匹配其实是nlp中的一个任务，之前叫语义相似度，现在所谓的文本匹配其实也是在做类似的事，说白了就是看俩句子有多相似，可以是01的分类问题，也可以是一个打分。

后面的这事我理解其实是一个检索任务，在整个库里面找到和给定query最相似的句子。而所谓的“相似”，却是需要定义的，不同的定义将会决定了查询和匹配的逻辑，如果把这个相似定义为语义或者文本相似，那就是对应所谓的“相似的标准“就是上面的文本匹配任务，看好，是标准是上面的语义匹配任务，我要吃肯德基和我要吃kfc很相似，所以召回的时候出现前者就应该查到后者，然而，如果定的相似的标准是“共现点击”，那又有另一套方法了。

讲到这，一言蔽之，nlp文本匹配问题是判断两个句子在语义层面的相似性，而后者，则是一个搜索问题，只不过在一定的场景下，可以用前者作为判断相似，判断搜索效果好坏的问题。

展开聊聊，nlp文本匹配主要分两个大的阶段，也形成了现在两个大的方法，文本和语义。最早没有深度学习的时候，文本匹配，就是字词层面的匹配就是主流，用户输入我要去长城，那带有长城的内容，还有带有“我要去""信息都可能被认为相似，八达岭长城，长城宽带，长城汽车，长城电影都有，也会有“我要去北京”，只不过因为我要去这种的idf比较低所以没那么相似，语义匹配则可以上升到更加模糊的语义层面，因为有我要去的存在，长城应该是地点，长城宽带之类的相似度也就下去了。具体不再展开了，有关领域我有总结自己的一套方法，可以参考一下：

而后面的检索任务，其实说白了就是一个查的问题，首先题主说的遍历，应该是最基本简单但不是最高效的方法，经典的搜索用的是“倒排索引”，文本层面最直接，数据库里面是存储的是“词汇-带有该词汇的文档id”，当查询的时候其实就是查这个词汇对应的文档，然后合并算分，复杂度可以被拉到和文档数无关的级别(体会到算法与数据结构的魅力了没？)，对于现在流行的向量召回，其实就是把文档转化向量存到一个空间里，查询的时候找到空间里最接近的那几个文档，向量可就不能直接倒排索引了，有特定的一套方法来处理，这个问题叫做“最近邻相似”，比较经典的方法就是统计学习方法knn那章提到的kdtree，后续有了ball tree等，到了现在hnsw，annoy，ngt之类的方案已经能让这个检索速度非常快(我自己的实验hnsw基本在十几纳秒每条的水平，应该没记错），具体的方案也可以去查查。

有关向量召回和向量表征的概念，我专门有写过文章，可以看看。有助于理解这些概念背后做的事，他们两者在应用场景下是非常相关的，一定程度的混淆非常正常。

另外再提醒一个事，有关“相似”，这个概念非常模糊，什么叫做相似往往是落地场景非常头疼问题，“六一节的由来”和“五一节的由来”，在直观的感受下是非常接近的，文本数字啥的很接近，但是因为我们赋予了五一和六一新的含义才导致了他们其实不相似，这些问题我们都要在定义清楚后告诉模型，模型才能够学到，这又是另一个问题了，这个问题先聊到这。"
刚确定研究方向是知识图谱方向，想请问该如何着手学习呢？,"首先，说一下我了解到的领域现状。随着人工智能技术的不断进步，认知智能的研究越来越受到学术界的重视。知识作为认知智能的核心元素之一，逐渐成为继数据、算法、算力后，第四个推动人工智能发展的关键要素。对于自然语言处理而言，要做到更精细的深度语义理解，单纯依靠海量数据来扩大模型规模的解决方案遇到越来越多的阻碍，而知识在语义理解上的作用不断凸显。知识图谱，作为当前最重要的知识表示形式，逐渐成为研究的热点。知识图谱是一个具有属性的实体通过关系连接而成的网状知识库，是知识的符号表达。本质上知识图谱技术从非结构化数据中抽取结构化知识，并将其组织为事实三元组的形式。通过知识图谱表示学习可以获得实体和关系的嵌入，从而与当前基于神经网络的模型融合，将实体和关系的知识隐式地融入到模型中。

学术上，关于知识图谱的研究主要集中在：知识图谱的自动构建（知识获取）和知识图谱的应用（知识应用）。现有的大型知识图谱，其构建过程依赖于结构或半结构数据，需要大量的人工介入，存在稀疏问题，我们希望能自动化地从非结构化文本数据中构建知识图谱，这就引出了知识获取。知识获取包括图谱补全、实体发现、关系抽取等步骤。实体发现可以分为实体识别、实体分类、实体连接等部分。应用方面，知识图谱和很多任务结合实现知识增强。知识图谱本身是个符号系统，知识图谱的表示学习通过从知识图谱学习得到实体和关系的嵌入，将知识融入到现有的neural model框架之下。有研究将知识图谱用于预训练语言模型，以丰富语言模型的常识，提高其在下游任务的表现。还有研究将知识图谱用于推荐系统、问答系统等等。

工程上，知识图谱正在应用于医疗、电商、金融等领域，而构建一个完整全面的知识图谱的成本仍然较高。不同行业的知识图谱构建差异性较大，需要结合行业特点和数据特点设计构建方案，仍然需要大量的人工/专家介入。

如上所述，知识图谱是多种技术交叉的领域，我的学习建议是先打好NLP的基础，剩下的在研究的过程中遇到了再补充。

入门建议

NLP的入门推荐一下manning的CS224n:

听课的过程中可以做下笔记，阅读相关论文并透彻搞懂一些经典工作如LSTM、attention、transformer、BERT。如果编程不过关的话也可以做一下作业。这样一遍下来基本上就可以读懂领域内的很多论文了。

另外研究知识图谱肯定绕不开的是图神经网络，有一个CS224w的课程可以学习一下：

这个课的主讲是Jure Leskovec大佬，如果英语不太好的话听这个课可能有点困难。

推荐三本书：

行业知识图谱构建：Domain-Specific Knowledge Graph Construction

两本GNN相关的书

刘知远老师的 Introduction to Graph Neural Networks

William L. Hamilton的 Graph Representation Learning

知识图谱方面目前没有很好的入门课程，可以先阅读一些综述文章对领域有个大致的认识，然后就是带着问题去阅读相关的论文，做研究。推荐一些综述：

知识图谱：

A Survey on Knowledge Graphs: Representation, Acquisition and Applications.论文链接

强烈推荐这一篇综述。

表示学习：

Knowledge graph embedding: A survey of approaches and applications.论文链接

Knowledge Representation Learning: A Quantitative Review.论文链接

知识应用

Introduction to neural network based approaches for question answering over knowledge graphs.论文链接

A Survey on Knowledge Graph-Based Recommender Systems.论文链接

然后还有我之前写过的一些综述，一起学习~



"
graph neural network,
alexnet多GPU使用时代码怎么写？,"出过书的工程师，讲课果然不一样，就是很透彻，很多东西能讲到精髓，让你豁然开朗。 1、AlexNet是计算机视觉领域的开山之作 2、2012年以超出第二名10.9个百分点的成绩夺冠 老师认为论文很重要，但是看论文的方法同样很重要，老师把自己读论文的经验技巧，和其他各路大神的私人秘籍，融合到视频里。

发布于 06-30 · 198 次播放"
